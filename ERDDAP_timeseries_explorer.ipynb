{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore ERDDAP timeseries data using Jupyter Widgets\n",
    "Inspired by [Jason Grout's excellent ESIP Tech Dive talk on \"Jupyter Widgets\"](https://youtu.be/CVcrTRQkTxo?t=2596), this notebook uses the `ipyleaflet` and `bqplot` widgets\n",
    "to interactively explore the last two weeks of time series data from an ERDDAP Server. Select a `standard_name` from the list, then click a station to see the time series.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.291663Z",
     "start_time": "2017-12-12T22:59:34.813470Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.636385Z",
     "start_time": "2017-12-12T22:59:37.299680Z"
    }
   },
   "outputs": [],
   "source": [
    "import pendulum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ipyleaflet` and `bqplot` are both Jupyter widgets, so can interact with Python like any other widget.  Since we want to click on a map in a notebook and get an interactive time series plot, they are perfect tools to use here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.755635Z",
     "start_time": "2017-12-12T22:59:37.643400Z"
    }
   },
   "outputs": [],
   "source": [
    "import bqplot as bq\n",
    "import ipyleaflet as ipyl\n",
    "import ipywidgets as ipyw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make working with ERDDAP simpler, we use `erddapy`, a high-level python interface to ERDDAP's RESTful API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.883904Z",
     "start_time": "2017-12-12T22:59:37.762650Z"
    }
   },
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP\n",
    "from erddapy.url_handling import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`quote` makes the url more readable for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import quote\n",
    "\n",
    "from requests import HTTPError\n",
    "from erddap_app.config import servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code should work with minor modifications on any ERDDAP (v1.64+) endpoint that has `cdm_data_type=timeseries` or `cdm_data_type=point` datasets.  Change the values for other ERDDAP endpoints or regions of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function puts lon,lat and datasetID into a GeoJSON feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.469131Z",
     "start_time": "2017-12-12T22:59:38.446082Z"
    }
   },
   "outputs": [],
   "source": [
    "def point(dataset, lon, lat, nchar):\n",
    "    geojsonFeature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {\"datasetID\": dataset, \"short_dataset_name\": dataset[:nchar]},\n",
    "        \"geometry\": {\"type\": \"Point\", \"coordinates\": [lon, lat]},\n",
    "    }\n",
    "    geojsonFeature[\"properties\"][\"style\"] = {\"color\": \"Grey\"}\n",
    "    return geojsonFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function finds all the datasets with a given standard_name in the specified time period, and return GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.518233Z",
     "start_time": "2017-12-12T22:59:38.476145Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_datasets(e, standard_name, cdm_data_type, min_time, max_time, skip_datasets):\n",
    "\n",
    "    search_url = e.get_search_url(\n",
    "        response=\"csv\",\n",
    "        cdm_data_type=cdm_data_type.lower(),\n",
    "        items_per_page=100000,\n",
    "        standard_name=standard_name,\n",
    "        min_time=min_time,\n",
    "        max_time=max_time,\n",
    "    )\n",
    "    try:\n",
    "        df = pd.read_csv(urlopen(search_url))\n",
    "\n",
    "        for skip_dataset in skip_datasets:\n",
    "            try:\n",
    "                row = df.loc[df[\"Dataset ID\"] == skip_dataset].index[0]\n",
    "                df.drop(row, inplace=True)\n",
    "            except IndexError:\n",
    "                continue\n",
    "\n",
    "    except HTTPError:\n",
    "        df = []\n",
    "        if len(var) > 14:\n",
    "            v = f\"{standard_name[:15]}...\"\n",
    "        else:\n",
    "            v = standard_name\n",
    "        figure.title = f\"No {v} found in this time range. Pick another variable.\"\n",
    "        figure.marks[0].y = 0.0 * figure.marks[0].y\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the lon,lat values from all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.542284Z",
     "start_time": "2017-12-12T22:59:38.526250Z"
    }
   },
   "outputs": [],
   "source": [
    "def all_datasets_locations(e, cdm_data_type, min_time, max_time):\n",
    "    url_dset = (\n",
    "        f\"{e.server}\"\n",
    "        \"/tabledap/allDatasets.csv?\"\n",
    "        \"datasetID,minLongitude,minLatitude&\"\n",
    "        f'cdm_data_type=\"{cdm_data_type}\"'\n",
    "        f\"&minTime<={max_time.to_datetime_string()}\"\n",
    "        f\"&maxTime>={min_time.to_datetime_string()}\"\n",
    "    )\n",
    "\n",
    "    url_dataset = quote(url_dset, safe=\":/?&= \")\n",
    "    del url_dset\n",
    "    df = pd.read_csv(urlopen(url_dataset), skiprows=[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns GeoJSON containing lon, lat and dataset ID for all matching stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.607420Z",
     "start_time": "2017-12-12T22:59:38.548296Z"
    }
   },
   "outputs": [],
   "source": [
    "def stdname2geojson(e, standard_name, cdm_data_type, min_time, max_time, skip_datasets):\n",
    "\n",
    "    dfsd = search_datasets(\n",
    "        e, standard_name, cdm_data_type, min_time, max_time, skip_datasets\n",
    "    )\n",
    "    if not dfsd.empty:\n",
    "        datasets = dfsd[\"Dataset ID\"].values\n",
    "\n",
    "        dfad = all_datasets_locations(e, cdm_data_type, min_time, max_time)\n",
    "        df = dfad[dfad[\"datasetID\"].isin(dfsd[\"Dataset ID\"])]\n",
    "        geojson = {\n",
    "            \"features\": [point(row[1], row[2], row[3], 3) for row in df.itertuples()]\n",
    "        }\n",
    "    else:\n",
    "        geojson = {\"features\": []}\n",
    "        datasets = []\n",
    "    return geojson, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `map_click_handler` function updates the time series plot when a station marker is clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.639488Z",
     "start_time": "2017-12-12T22:59:38.615437Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_click_handler(event=None, id=None, properties=None, feature=None):\n",
    "\n",
    "    dataset_id = properties[\"datasetID\"]\n",
    "\n",
    "    min_time = pendulum.parse(widget_search_min_time.value)\n",
    "    max_time = pendulum.parse(widget_search_max_time.value)\n",
    "    constraints = {\"time>=\": min_time, \"time<=\": max_time}\n",
    "\n",
    "    standard_name = widget_std_names.value\n",
    "    widget_dsnames.value = dataset_id\n",
    "    \n",
    "    try:\n",
    "        update_timeseries_plot(e,\n",
    "            dataset=dataset_id, standard_name=standard_name, constraints=constraints\n",
    "        )\n",
    "    except HTTPError:\n",
    "        print(\n",
    "            \"No\", standard_name, \"data for this station. Please choose another station.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `widget_replot_button_handler` function updates the time series plot when the `Update TimeSeries` button is selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widget_replot_button_handler(change):\n",
    "    \n",
    "    plot_start_time = pendulum.parse(widget_plot_start_time.value)\n",
    "    plot_stop_time = pendulum.parse(widget_plot_stop_time.value)\n",
    "\n",
    "    constraints = {\"time>=\": plot_start_time, \"time<=\": plot_stop_time}\n",
    "    dataset_id = widget_dsnames.value\n",
    "    update_timeseries_plot(e,\n",
    "        dataset=dataset_id, standard_name=widget_std_names.value, constraints=constraints\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `widget_search_button_handler` function updates the map when the `Update Search` button is selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.686586Z",
     "start_time": "2017-12-12T22:59:38.646502Z"
    }
   },
   "outputs": [],
   "source": [
    "def widget_search_button_handler(change):\n",
    "    \n",
    "    min_time = pendulum.parse(widget_search_min_time.value)\n",
    "    max_time = pendulum.parse(widget_search_max_time.value)\n",
    "\n",
    "    standard_name = widget_std_names.value\n",
    "\n",
    "    features, datasets = stdname2geojson(\n",
    "        e,\n",
    "        standard_name,\n",
    "        server.get(\"cdm_data_type\"),\n",
    "        min_time,\n",
    "        max_time,\n",
    "        server.get(\"skip_datasets\"),\n",
    "    )\n",
    "\n",
    "    feature_layer = ipyl.GeoJSON(data=features)\n",
    "    constraints = {\"time>=\": min_time, \"time<=\": max_time}\n",
    "    \n",
    "    feature_layer.on_click(map_click_handler)\n",
    "    map.layers = [map.layers[0], feature_layer]\n",
    "\n",
    "    dataset_id = datasets[0]\n",
    "    widget_dsnames.options = datasets\n",
    "    widget_dsnames.value = dataset_id\n",
    "    \n",
    "    update_timeseries_plot(e,\n",
    "        dataset=dataset_id, standard_name=standard_name, constraints=constraints\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function updates the time series plot when the `Update Search` or the `Update TimeSeries` button is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_timeseries_plot(e=None,\n",
    "    dataset=None, standard_name=None, constraints=None, title_len=18\n",
    "):\n",
    "    df, var = get_timeseries(e,\n",
    "        dataset=dataset, standard_name=standard_name, constraints=constraints\n",
    "    )\n",
    "    figure.marks[0].x = df.index\n",
    "    figure.marks[0].y = df[var]\n",
    "    figure.title = f\"{dataset[:title_len]} - {var}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the specified dataset time series values as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.767756Z",
     "start_time": "2017-12-12T22:59:38.743706Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_timeseries(e, dataset=None, standard_name=None, constraints=None):\n",
    "    var = e.get_var_by_attr(\n",
    "        dataset_id=dataset,\n",
    "        standard_name=lambda v: str(v).lower() == standard_name.lower(),\n",
    "    )\n",
    "    if var:\n",
    "        var = var[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot get data for {standard_name}.\")\n",
    "        # We should filter out only valid standard_names for each dataset!\n",
    "        # df = pd.read_csv(e.get_info_url(response=\"csv\"))\n",
    "        # df.loc[df[\"Attribute Name\"] == \"standard_name\"][\"Value\"].values\n",
    "\n",
    "    download_url = e.get_download_url(\n",
    "        dataset_id=dataset,\n",
    "        constraints=constraints,\n",
    "        variables=[\"time\", var],\n",
    "        response=\"csv\",\n",
    "    )\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        urlopen(download_url), index_col=\"time\", parse_dates=True, skiprows=[1]\n",
    "    )\n",
    "    return df, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.915971Z",
     "start_time": "2017-12-12T22:59:37.890919Z"
    }
   },
   "outputs": [],
   "source": [
    "# now = pendulum.now(tz=\"utc\")\n",
    "\n",
    "# servers = {\n",
    "#     \"ioos\": {\n",
    "#         \"url\": \"http://erddap.sensors.ioos.us/erddap\",\n",
    "#         \"standard_name\": \"sea_surface_wave_significant_height\",\n",
    "#         \"nchar\": 9,\n",
    "#         \"cdm_data_type\": \"TimeSeries\",\n",
    "#         \"center\": [35, -100],\n",
    "#         \"zoom\": 3,\n",
    "#         \"max_time\": pendulum.parse(\"2017-11-11T00:00:00Z\"),\n",
    "#         \"min_time\": pendulum.parse(\"2017-11-01T00:00:00Z\"),\n",
    "#         \"skip_datasets\": [],\n",
    "#     },\n",
    "#     \"whoi\": {\n",
    "#         \"url\": \"https://gamone.whoi.edu/erddap\",\n",
    "#         \"standard_name\": \"sea_water_temperature\",\n",
    "#         \"nchar\": 9,\n",
    "#         \"cdm_data_type\": \"TimeSeries\",\n",
    "#         \"center\": [35, -100],\n",
    "#         \"zoom\": 3,\n",
    "#         \"max_time\": pendulum.parse(\"2011-05-15T00:00:00Z\"),\n",
    "#         \"min_time\": pendulum.parse(\"2011-05-05T00:00:00Z\"),\n",
    "#         \"skip_datasets\": [],\n",
    "#     },\n",
    "#     \"ooi\": {\n",
    "#         \"url\": \"https://erddap-uncabled.oceanobservatories.org/uncabled/erddap\",\n",
    "#         \"standard_name\": \"sea_water_temperature\",\n",
    "#         \"nchar\": 8,\n",
    "#         \"cdm_data_type\": \"Point\",\n",
    "#         \"center\": [35, -100],\n",
    "#         \"zoom\": 1,\n",
    "#         \"max_time\": pendulum.parse(\"2017-08-03T00:00:00Z\"),\n",
    "#         \"min_time\": pendulum.parse(\"2017-08-01T00:00:00Z\"),\n",
    "#         \"skip_datasets\": [],\n",
    "#     },\n",
    "#     \"neracoos\": {\n",
    "#         \"url\": \"http://www.neracoos.org/erddap\",\n",
    "#         \"standard_name\": \"significant_height_of_wind_and_swell_waves\",\n",
    "#         \"nchar\": 3,\n",
    "#         \"cdm_data_type\": \"TimeSeries\",\n",
    "#         \"center\": [42.5, -68],\n",
    "#         \"zoom\": 6,\n",
    "#         \"max_time\": now,\n",
    "#         \"min_time\": now.subtract(weeks=2),\n",
    "#         \"skip_datasets\": [\"cwwcNDBCMet\"],\n",
    "#     },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_name = \"neracoos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell specifies the standard names to be skipped, such as quality control-related and time-invariant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_qcstdnames(standard_names):\n",
    "    qc = re.compile(\"^.*(qc)$|^.*(data_quality)$|^.*(flag)$\")\n",
    "    qc_stdnames = list(filter(qc.search, standard_names))\n",
    "    del qc\n",
    "    \n",
    "    skip_stdnames = [\n",
    "        \"depth\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"platform\",\n",
    "        \"station_name\",\n",
    "        \"time\",\n",
    "        \"offset_time\",\n",
    "    ]\n",
    "    skip_stdnames.extend(qc_stdnames)\n",
    "    del qc_stdnames\n",
    "    \n",
    "    for skip_stdname in skip_stdnames:\n",
    "        try:\n",
    "            standard_names.remove(skip_stdname)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    del skip_stdname\n",
    "    return standard_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell identifies the valid standard names for the specified server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_stdnames(server_name):\n",
    "    server = servers[server_name]\n",
    "    server_url = server.get(\"url\")\n",
    "    \n",
    "    e = ERDDAP(server=server_url, protocol=\"tabledap\")\n",
    "    \n",
    "    url_standard_names = f\"{server_url}/categorize/standard_name/index.csv\"\n",
    "    df = pd.read_csv(urlopen(url_standard_names), skiprows=[1, 2])\n",
    "    standard_names = list(df[\"Category\"].values)\n",
    "\n",
    "    standard_names = remove_qcstdnames(standard_names)\n",
    "\n",
    "    valid_standard_names = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    print(\n",
    "        \"Checking the variables available for this server. This might take up to a couple of minutes...\\n\"\n",
    "    )\n",
    "\n",
    "    for standard_name in standard_names:\n",
    "    \n",
    "        count += 1\n",
    "\n",
    "        if count == np.floor(len(standard_names) / 2):\n",
    "            print(\"Halfway there...\\n\")\n",
    "        elif count == np.floor((len(standard_names) / 4) * 3):\n",
    "            print(\"Almost done...\\n\")\n",
    "        elif count == (len(standard_names)):\n",
    "            print(\"Done!\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            features, datasets = stdname2geojson(\n",
    "                e,\n",
    "                standard_name,\n",
    "                server.get(\"cdm_data_type\"),\n",
    "                server.get(\"min_time\"),\n",
    "                server.get(\"max_time\"),\n",
    "                server.get(\"skip_datasets\"),\n",
    "            )\n",
    "        except NameError:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "\n",
    "            var = e.get_var_by_attr(\n",
    "                dataset_id=datasets[0],\n",
    "                standard_name=lambda v: str(v).lower() == standard_name.lower(),\n",
    "            )\n",
    "\n",
    "            if var != []:\n",
    "                valid_standard_names.append(standard_name)\n",
    "\n",
    "        except IndexError:\n",
    "            del features, datasets\n",
    "            continue\n",
    "\n",
    "    del count, standard_names, standard_name\n",
    "    return valid_standard_names, server, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the variables available for this server. This might take up to a couple of minutes...\n",
      "\n",
      "Halfway there...\n",
      "\n",
      "Almost done...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "valid_standard_names, server, e = get_valid_stdnames(server_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dropdown menu widget with all the valid `standard_name` values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_std_names(server,valid_standard_names):\n",
    "    widget_std_names = ipyw.Dropdown(\n",
    "        options=valid_standard_names, \n",
    "        value=server.get(\"standard_name\")\n",
    "        )   \n",
    "    return widget_std_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a text widget to enter the search minimum time and maximum time for the datasets search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_search_min_time(server):\n",
    "    widget_search_min_time = ipyw.Text(\n",
    "        value=server.get(\"min_time\").to_datetime_string(),\n",
    "        description=\"Search Min\",\n",
    "        disabled=False,\n",
    "        )\n",
    "    return widget_search_min_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_search_max_time(server):\n",
    "    widget_search_max_time = ipyw.Text(\n",
    "        value=server.get(\"max_time\").to_datetime_string(),\n",
    "        description=\"Search Max\",\n",
    "        disabled=False,\n",
    "        )\n",
    "    return widget_search_max_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `Update Search` button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.720658Z",
     "start_time": "2017-12-12T22:59:38.692599Z"
    }
   },
   "outputs": [],
   "source": [
    "widget_search_button = ipyw.Button(\n",
    "    value=False, description=\"Update Search\", disabled=False, button_style=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a text widget to enter the search minimum and maximum time for the time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_plot_start_time(server):\n",
    "    widget_plot_start_time = ipyw.Text(\n",
    "        value=server.get(\"min_time\").to_datetime_string(),\n",
    "        description=\"Plot Min\",\n",
    "        disabled=False,\n",
    "        )\n",
    "    return widget_plot_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_plot_stop_time(server):\n",
    "    widget_plot_stop_time = ipyw.Text(\n",
    "        value=server.get(\"max_time\").to_datetime_string(),\n",
    "        description=\"Plot Max\",\n",
    "        disabled=False,\n",
    "        )\n",
    "    return widget_plot_stop_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `Update TimeSeries` button "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_replot_button = ipyw.Button(\n",
    "    value=False, description=\"Update TimeSeries\", disabled=False, button_style=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_replot_button.on_click(widget_replot_button_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.736691Z",
     "start_time": "2017-12-12T22:59:38.728674Z"
    }
   },
   "outputs": [],
   "source": [
    "widget_search_button.on_click(widget_search_button_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the initial `ipyleaflet` map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.963166Z",
     "start_time": "2017-12-12T22:59:38.808842Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_datasets(server, e):\n",
    "    map = ipyl.Map(\n",
    "        center=server.get(\"center\"),\n",
    "        zoom=server.get(\"zoom\"),\n",
    "        layout=dict(width=\"750px\", height=\"350px\"),\n",
    "    )\n",
    "    features, datasets = stdname2geojson(\n",
    "        e,\n",
    "        server.get(\"standard_name\"),\n",
    "        server.get(\"cdm_data_type\"),\n",
    "        server.get(\"min_time\"),\n",
    "        server.get(\"max_time\"),\n",
    "        server.get(\"skip_datasets\"),\n",
    "    )\n",
    "    dataset_id = datasets[0]\n",
    "    feature_layer = ipyl.GeoJSON(data=features)\n",
    "    feature_layer.on_click(map_click_handler)\n",
    "    map.layers = [map.layers[0], feature_layer]\n",
    "    return map, feature_layer, datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_dsnames(datasets):\n",
    "    dataset_id = datasets[0]\n",
    "    widget_dsnames = ipyw.Dropdown(options=datasets, value=dataset_id)\n",
    "    return widget_dsnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the initial `bqplot` time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:43.043717Z",
     "start_time": "2017-12-12T22:59:38.968176Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_timeseries(server, e, dataset_id):\n",
    "    dt_x = bq.DateScale()\n",
    "    sc_y = bq.LinearScale()\n",
    "\n",
    "    constraints = {\"time>=\": server.get(\"min_time\"), \"time<=\": server.get(\"max_time\")}\n",
    "\n",
    "    df, var = get_timeseries(e,\n",
    "        dataset=dataset_id,\n",
    "        standard_name=server.get(\"standard_name\"),\n",
    "        constraints=constraints,\n",
    "    )\n",
    "    def_tt = bq.Tooltip(fields=[\"y\"], formats=[\".2f\"], labels=[\"value\"])\n",
    "    time_series = bq.Lines(\n",
    "        x=df.index, y=df[var], scales={\"x\": dt_x, \"y\": sc_y}, tooltip=def_tt\n",
    "    )\n",
    "    ax_x = bq.Axis(scale=dt_x, label=\"Time\")\n",
    "    ax_y = bq.Axis(scale=sc_y, orientation=\"vertical\")\n",
    "    figure = bq.Figure(marks=[time_series], axes=[ax_x, ax_y])\n",
    "    figure.title = f\"{dataset_id[:18]} - {var}\"\n",
    "    figure.layout.height = \"300px\"\n",
    "    figure.layout.width = \"800px\"\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space():\n",
    "    ispace = ipyw.HTML(\n",
    "        value='<style>  .space {margin-bottom: 6.5cm;}</style><p class=\"space\"> </p>',\n",
    "        placeholder=\"\",\n",
    "        description=\"\",\n",
    "    )\n",
    "    return ispace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "map, feature_layer, datasets = plot_datasets(server, e)\n",
    "figure = plot_timeseries(server, e, datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_std_names = f_widget_std_names(server, valid_standard_names)\n",
    "widget_search_min_time = f_widget_search_min_time(server)\n",
    "widget_search_max_time = f_widget_search_max_time(server)\n",
    "widget_plot_start_time = f_widget_plot_start_time(server)\n",
    "widget_plot_stop_time = f_widget_plot_stop_time(server)\n",
    "widget_dsnames = f_widget_dsnames(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ispace = space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specifies the widget layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:43.460591Z",
     "start_time": "2017-12-12T22:59:43.181005Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c3d1eb93fb4384a6b8cac5db12e160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(Map(center=[42.5, -68], controls=(ZoomControl(options=['position', 'zoom_in_text',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "form_item_layout = ipyw.Layout(\n",
    "    display=\"flex\", flex_flow=\"column\", justify_content=\"space-between\"\n",
    ")\n",
    "\n",
    "col1 = ipyw.Box([map, figure], layout=form_item_layout)\n",
    "col2 = ipyw.Box(\n",
    "    [\n",
    "        widget_std_names,\n",
    "        widget_search_min_time,\n",
    "        widget_search_max_time,\n",
    "        widget_search_button,\n",
    "        ispace,\n",
    "        widget_dsnames,\n",
    "        widget_plot_start_time,\n",
    "        widget_plot_stop_time,\n",
    "        widget_replot_button,\n",
    "    ],\n",
    "    layout=form_item_layout,\n",
    ")\n",
    "\n",
    "form_items = [col1, col2]\n",
    "\n",
    "form = ipyw.Box(\n",
    "    form_items,\n",
    "    layout=ipyw.Layout(\n",
    "        display=\"flex\",\n",
    "        flex_flow=\"row\",\n",
    "        border=\"solid 2px\",\n",
    "        align_items=\"flex-start\",\n",
    "        width=\"100%\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python4widgets",
   "language": "python",
   "name": "widgets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
