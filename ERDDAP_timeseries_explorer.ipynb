{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore ERDDAP timeseries data using Jupyter Widgets\n",
    "Inspired by [Jason Grout's excellent ESIP Tech Dive talk on \"Jupyter Widgets\"](https://youtu.be/CVcrTRQkTxo?t=2596), this notebook uses the `ipyleaflet` and `bqplot` widgets\n",
    "to interactively explore the last two weeks of time series data from an ERDDAP Server. Select a `standard_name` from the list, then click a station to see the time series.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T22:00:31.001042Z",
     "start_time": "2017-12-06T22:00:30.979029Z"
    }
   },
   "source": [
    "NOTE: To access a protected ERDDAP endpoint is protected, you can add a `~/.netrc` file like this:\n",
    "```\n",
    "machine cgoms.coas.oregonstate.edu\n",
    "login <username>\n",
    "password <password>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.291663Z",
     "start_time": "2017-12-12T22:59:34.813470Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.636385Z",
     "start_time": "2017-12-12T22:59:37.299680Z"
    }
   },
   "outputs": [],
   "source": [
    "import pendulum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ipyleaflet` and `bqplot` are both Jupyter widgets, so can interact with Python like any other widget.  Since we want to click on a map in a notebook and get an interactive time series plot, they are perfect tools to use here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.755635Z",
     "start_time": "2017-12-12T22:59:37.643400Z"
    }
   },
   "outputs": [],
   "source": [
    "import bqplot as bq\n",
    "import ipyleaflet as ipyl\n",
    "import ipywidgets as ipyw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make working with ERDDAP simpler, we use `erddapy`, a high-level python interface to ERDDAP's RESTful API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.883904Z",
     "start_time": "2017-12-12T22:59:37.762650Z"
    }
   },
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP\n",
    "from erddapy.url_handling import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code should work with minor modifications on any ERDDAP (v1.64+) endpoint that has `cdm_data_type=timeseries` or `cdm_data_type=point` datasets.  Change the values for other ERDDAP endpoints or regions of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function puts lon,lat and datasetID into a GeoJSON feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.469131Z",
     "start_time": "2017-12-12T22:59:38.446082Z"
    }
   },
   "outputs": [],
   "source": [
    "def point(dataset, lon, lat, nchar):\n",
    "    geojsonFeature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {\"datasetID\": dataset, \"short_dataset_name\": dataset[:nchar]},\n",
    "        \"geometry\": {\"type\": \"Point\", \"coordinates\": [lon, lat]},\n",
    "    }\n",
    "    geojsonFeature[\"properties\"][\"style\"] = {\"color\": \"Grey\"}\n",
    "    return geojsonFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function finds all the datasets with a given standard_name in the specified time period, and return GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.518233Z",
     "start_time": "2017-12-12T22:59:38.476145Z"
    }
   },
   "outputs": [],
   "source": [
    "def adv_search(e, standard_name, cdm_data_type, min_time, max_time):\n",
    "    try:\n",
    "        search_url = e.get_search_url(\n",
    "            response=\"csv\",\n",
    "            cdm_data_type=cdm_data_type.lower(),\n",
    "            items_per_page=100000,\n",
    "            standard_name=standard_name,\n",
    "            min_time=min_time,\n",
    "            max_time=max_time,\n",
    "        )\n",
    "        df = pd.read_csv(urlopen(search_url))\n",
    "    except:\n",
    "        df = []\n",
    "        if len(var) > 14:\n",
    "            v = \"{}...\".format(standard_name[:15])\n",
    "        else:\n",
    "            v = standard_name\n",
    "        figure.title = \"No {} found in this time range. Pick another variable.\".format(\n",
    "            v\n",
    "        )\n",
    "        figure.marks[0].y = 0.0 * figure.marks[0].y\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the lon,lat values from allDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.542284Z",
     "start_time": "2017-12-12T22:59:38.526250Z"
    }
   },
   "outputs": [],
   "source": [
    "def alllonlat(e, cdm_data_type, min_time, max_time):\n",
    "    url_dataset = \"{}/tabledap/allDatasets.csv?datasetID%2CminLongitude%2CminLatitude&cdm_data_type=%22{}%22&minTime%3C={}&maxTime%3E={}\".format(\n",
    "        e.server,\n",
    "        cdm_data_type,\n",
    "        max_time.to_datetime_string(),\n",
    "        min_time.to_datetime_string(),\n",
    "    )\n",
    "    df = pd.read_csv(urlopen(url_dataset), skiprows=[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.607420Z",
     "start_time": "2017-12-12T22:59:38.548296Z"
    }
   },
   "outputs": [],
   "source": [
    "def stdname2geojson(e, standard_name, cdm_data_type, min_time, max_time):\n",
    "    \"\"\"return geojson containing lon, lat and datasetID for all matching stations\"\"\"\n",
    "\n",
    "    dfa = adv_search(e, standard_name, cdm_data_type, min_time, max_time)\n",
    "    if isinstance(dfa, pd.DataFrame):\n",
    "        datasets = dfa[\"Dataset ID\"].values\n",
    "\n",
    "        dfll = alllonlat(e, cdm_data_type, min_time, max_time)\n",
    "        dfr = dfll[dfll[\"datasetID\"].isin(dfa[\"Dataset ID\"])]\n",
    "        geojson = {\n",
    "            \"features\": [point(row[1], row[2], row[3], 3) for row in dfr.itertuples()]\n",
    "        }\n",
    "    else:\n",
    "        geojson = {\"features\": []}\n",
    "        datasets = []\n",
    "    return geojson, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `map_click_handler` function updates the time series plot when a station marker is clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.639488Z",
     "start_time": "2017-12-12T22:59:38.615437Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_click_handler(event=None, id=None, properties=None, feature=None):\n",
    "    global dataset_id, standard_name\n",
    "    dataset_id = properties[\"datasetID\"]\n",
    "\n",
    "    standard_name = widget_std_names.value\n",
    "    widget_dsnames.value = dataset_id\n",
    "    try:\n",
    "        update_timeseries_plot(\n",
    "            dataset=dataset_id, standard_name=standard_name, constraints=constraints\n",
    "        )\n",
    "    except:\n",
    "        print(\n",
    "            \"No\", standard_name, \"data for this station. Please choose another station.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `search_button_handler` function updates the map when the `Search` button is selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widget_replot_button_handler(change):\n",
    "    global dataset_id, constraints\n",
    "    plot_start_time = pendulum.parse(widget_plot_start_time.value)\n",
    "    plot_stop_time = pendulum.parse(widget_plot_stop_time.value)\n",
    "\n",
    "    constraints = {\"time>=\": plot_start_time, \"time<=\": plot_stop_time}\n",
    "    dataset_id = widget_dsnames.value\n",
    "    update_timeseries_plot(\n",
    "        dataset=dataset_id, standard_name=standard_name, constraints=constraints\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.686586Z",
     "start_time": "2017-12-12T22:59:38.646502Z"
    }
   },
   "outputs": [],
   "source": [
    "def widget_search_button_handler(change):\n",
    "    global features, datasets, standard_name, dataset_id, constraints\n",
    "    min_time = pendulum.parse(widget_search_min_time.value)\n",
    "    max_time = pendulum.parse(widget_search_max_time.value)\n",
    "\n",
    "    standard_name = widget_std_names.value\n",
    "\n",
    "    features, datasets = stdname2geojson(\n",
    "        e,\n",
    "        standard_name,\n",
    "        server.get(\"cdm_data_type\"),\n",
    "        min_time,\n",
    "        max_time,\n",
    "    )\n",
    "\n",
    "    feature_layer = ipyl.GeoJSON(data=features)\n",
    "    feature_layer.on_click(map_click_handler)\n",
    "    map.layers = [map.layers[0], feature_layer]\n",
    "\n",
    "    dataset_id = datasets[0]\n",
    "    widget_dsnames.options = datasets\n",
    "    widget_dsnames.value = dataset_id\n",
    "\n",
    "    constraints = {\"time>=\": min_time, \"time<=\": max_time}\n",
    "    update_timeseries_plot(\n",
    "        dataset=dataset_id, standard_name=standard_name, constraints=constraints\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_timeseries_plot(\n",
    "    dataset=None, standard_name=None, constraints=None, title_len=18\n",
    "):\n",
    "    df, var = get_data(\n",
    "        dataset=dataset, standard_name=standard_name, constraints=constraints\n",
    "    )\n",
    "    figure.marks[0].x = df.index\n",
    "    figure.marks[0].y = df[var]\n",
    "    figure.title = \"{} - {}\".format(dataset[:title_len], var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the specified dataset time series values as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.767756Z",
     "start_time": "2017-12-12T22:59:38.743706Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(dataset=None, standard_name=None, constraints=None):\n",
    "    var = e.get_var_by_attr(\n",
    "        dataset_id=dataset,\n",
    "        standard_name=lambda v: str(v).lower() == standard_name.lower(),\n",
    "    )\n",
    "    if var:\n",
    "        var = var[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot get data for {standard_name}.\")\n",
    "        # We should filter out only valid standard_names for each dataset!\n",
    "        # df = pd.read_csv(e.get_info_url(response=\"csv\"))\n",
    "        # df.loc[df[\"Attribute Name\"] == \"standard_name\"][\"Value\"].values\n",
    "\n",
    "    download_url = e.get_download_url(\n",
    "        dataset_id=dataset,\n",
    "        constraints=constraints,\n",
    "        variables=[\"time\", var],\n",
    "        response=\"csv\",\n",
    "    )\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        urlopen(download_url), index_col=\"time\", parse_dates=True, skiprows=[1]\n",
    "    )\n",
    "    return df, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.915971Z",
     "start_time": "2017-12-12T22:59:37.890919Z"
    }
   },
   "outputs": [],
   "source": [
    "now = pendulum.now(tz=\"utc\")\n",
    "\n",
    "servers = {\n",
    "    \"ioos\": {\n",
    "        \"url\": \"http://erddap.sensors.ioos.us/erddap\",\n",
    "        \"standard_name\": \"sea_surface_wave_significant_height\",\n",
    "        \"nchar\": 9,\n",
    "        \"cdm_data_type\": \"TimeSeries\",\n",
    "        \"center\": [35, -100],\n",
    "        \"zoom\": 3,\n",
    "        \"max_time\": pendulum.parse(\"2017-11-11T00:00:00Z\"),\n",
    "        \"min_time\": pendulum.parse(\"2017-11-01T00:00:00Z\"),\n",
    "    },\n",
    "    \"whoi\": {\n",
    "        \"url\": \"https://gamone.whoi.edu/erddap\",\n",
    "        \"standard_name\": \"sea_water_temperature\",\n",
    "        \"nchar\": 9,\n",
    "        \"cdm_data_type\": \"TimeSeries\",\n",
    "        \"center\": [35, -100],\n",
    "        \"zoom\": 3,\n",
    "        \"max_time\": pendulum.parse(\"2011-05-15T00:00:00Z\"),\n",
    "        \"min_time\": pendulum.parse(\"2011-05-05T00:00:00Z\"),\n",
    "    },\n",
    "    \"ooi\": {\n",
    "        \"url\": \"https://erddap-uncabled.oceanobservatories.org/uncabled/erddap\",\n",
    "        \"standard_name\": \"sea_water_temperature\",\n",
    "        \"nchar\": 8,\n",
    "        \"cdm_data_type\": \"Point\",\n",
    "        \"center\": [35, -100],\n",
    "        \"zoom\": 1,\n",
    "        \"max_time\": pendulum.parse(\"2017-08-03T00:00:00Z\"),\n",
    "        \"min_time\": pendulum.parse(\"2017-08-01T00:00:00Z\"),\n",
    "    },\n",
    "    \"neracoos\": {\n",
    "        \"url\": \"http://www.neracoos.org/erddap\",\n",
    "        \"standard_name\": \"significant_height_of_wind_and_swell_waves\",\n",
    "        \"nchar\": 3,\n",
    "        \"cdm_data_type\": \"TimeSeries\",\n",
    "        \"center\": [42.5, -68],\n",
    "        \"zoom\": 6,\n",
    "        \"max_time\": now,\n",
    "        \"min_time\": now.subtract(weeks=2),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_name = \"ooi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = servers[server_name]\n",
    "server_url = server.get(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.187540Z",
     "start_time": "2017-12-12T22:59:38.110379Z"
    }
   },
   "outputs": [],
   "source": [
    "e = ERDDAP(server=server_url, protocol=\"tabledap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the `standard_name` attributes that exist on this ERDDAP endpoint, using [ERDDAP's \"categorize\" service](http://www.neracoos.org/erddap/categorize/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.272719Z",
     "start_time": "2017-12-12T22:59:38.195557Z"
    }
   },
   "outputs": [],
   "source": [
    "url_standard_names = f\"{server_url}/categorize/standard_name/index.csv\"\n",
    "df = pd.read_csv(urlopen(url_standard_names), skiprows=[1, 2])\n",
    "standard_names = df[\"Category\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell identifies the valid standard names for the specified server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the variables available for this server. This might take up to a couple of minutes...\n",
      "\n",
      "Halfway there...\n",
      "\n",
      "Almost done...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "valid_standard_names = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "print(\n",
    "    \"Checking the variables available for this server. This might take up to a couple of minutes...\\n\"\n",
    ")\n",
    "\n",
    "for standard_name in standard_names:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    if count == np.floor(len(standard_names) / 2):\n",
    "        print(\"Halfway there...\\n\")\n",
    "    elif count == np.floor((len(standard_names) / 4) * 3):\n",
    "        print(\"Almost done...\\n\")\n",
    "    elif count == (len(standard_names)):\n",
    "        print(\"Done!\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        features, datasets = stdname2geojson(\n",
    "            e,\n",
    "            standard_name,\n",
    "            server.get(\"cdm_data_type\"),\n",
    "            server.get(\"min_time\"),\n",
    "            server.get(\"max_time\"),\n",
    "        )\n",
    "\n",
    "        var = e.get_var_by_attr(\n",
    "            dataset_id=datasets[0],\n",
    "            standard_name=lambda v: str(v).lower() == standard_name.lower(),\n",
    "        )\n",
    "\n",
    "        if var != []:\n",
    "            valid_standard_names.append(standard_name)\n",
    "\n",
    "        del var, features, datasets\n",
    "\n",
    "    except NameError:\n",
    "        continue\n",
    "del count, standard_names, standard_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dropdown menu widget with all the `standard_name` values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.323826Z",
     "start_time": "2017-12-12T22:59:38.279734Z"
    }
   },
   "outputs": [],
   "source": [
    "widget_std_names = ipyw.Dropdown(\n",
    "    options=valid_standard_names, value=server.get(\"standard_name\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a text widget to enter the search minimum time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_search_min_time = ipyw.Text(\n",
    "    value=server.get(\"min_time\").to_datetime_string(),\n",
    "    description=\"Search Min\",\n",
    "    disabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.371927Z",
     "start_time": "2017-12-12T22:59:38.330841Z"
    }
   },
   "outputs": [],
   "source": [
    "widget_search_max_time = ipyw.Text(\n",
    "    value=server.get(\"max_time\").to_datetime_string(),\n",
    "    description=\"Search Max\",\n",
    "    disabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.720658Z",
     "start_time": "2017-12-12T22:59:38.692599Z"
    }
   },
   "outputs": [],
   "source": [
    "widget_search_button = ipyw.Button(\n",
    "    value=False, description=\"Update search\", disabled=False, button_style=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_plot_start_time = ipyw.Text(\n",
    "    value=server.get(\"min_time\").to_datetime_string(),\n",
    "    description=\"Plot Min\",\n",
    "    disabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_plot_stop_time = ipyw.Text(\n",
    "    value=server.get(\"max_time\").to_datetime_string(),\n",
    "    description=\"Plot Max\",\n",
    "    disabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_replot_button = ipyw.Button(\n",
    "    value=False, description=\"Update TimeSeries\", disabled=False, button_style=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_replot_button.on_click(widget_replot_button_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.736691Z",
     "start_time": "2017-12-12T22:59:38.728674Z"
    }
   },
   "outputs": [],
   "source": [
    "widget_search_button.on_click(widget_search_button_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the initial `ipyleaflet` map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.963166Z",
     "start_time": "2017-12-12T22:59:38.808842Z"
    }
   },
   "outputs": [],
   "source": [
    "map = ipyl.Map(\n",
    "    center=server.get(\"center\"),\n",
    "    zoom=server.get(\"zoom\"),\n",
    "    layout=dict(width=\"750px\", height=\"350px\"),\n",
    ")\n",
    "features, datasets = stdname2geojson(\n",
    "    e,\n",
    "    server.get(\"standard_name\"),\n",
    "    server.get(\"cdm_data_type\"),\n",
    "    server.get(\"min_time\"),\n",
    "    server.get(\"max_time\"),\n",
    ")\n",
    "dataset_id = datasets[0]\n",
    "feature_layer = ipyl.GeoJSON(data=features)\n",
    "feature_layer.on_click(map_click_handler)\n",
    "map.layers = [map.layers[0], feature_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.800826Z",
     "start_time": "2017-12-12T22:59:38.774771Z"
    }
   },
   "outputs": [],
   "source": [
    "widget_dsnames = ipyw.Dropdown(options=datasets, value=dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the initial `bqplot` time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:43.043717Z",
     "start_time": "2017-12-12T22:59:38.968176Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_x = bq.DateScale()\n",
    "sc_y = bq.LinearScale()\n",
    "\n",
    "constraints = {\"time>=\": server.get(\"min_time\"), \"time<=\": server.get(\"max_time\")}\n",
    "\n",
    "df, var = get_data(\n",
    "    dataset=dataset_id,\n",
    "    standard_name=server.get(\"standard_name\"),\n",
    "    constraints=constraints,\n",
    ")\n",
    "def_tt = bq.Tooltip(fields=[\"y\"], formats=[\".2f\"], labels=[\"value\"])\n",
    "time_series = bq.Lines(\n",
    "    x=df.index, y=df[var], scales={\"x\": dt_x, \"y\": sc_y}, tooltip=def_tt\n",
    ")\n",
    "ax_x = bq.Axis(scale=dt_x, label=\"Time\")\n",
    "ax_y = bq.Axis(scale=sc_y, orientation=\"vertical\")\n",
    "figure = bq.Figure(marks=[time_series], axes=[ax_x, ax_y])\n",
    "figure.title = \"{} - {}\".format(dataset_id[:18], var)\n",
    "figure.layout.height = \"300px\"\n",
    "figure.layout.width = \"800px\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ispace = ipyw.HTML(\n",
    "    value='<style>  .space {margin-bottom: 6.5cm;}</style><p class=\"space\"> </p>',\n",
    "    placeholder=\"\",\n",
    "    description=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specifies the widget layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:43.460591Z",
     "start_time": "2017-12-12T22:59:43.181005Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23766bd94a3420488237dc0c807f4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(Map(center=[35, -100], controls=(ZoomControl(options=['position', 'zoom_in_text', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "HTTPError",
     "evalue": "<!DOCTYPE html><html><head><title>Apache Tomcat/8.0.33 - Error report</title><style type=\"text/css\">H1 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:22px;} H2 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:16px;} H3 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:14px;} BODY {font-family:Tahoma,Arial,sans-serif;color:black;background-color:white;} B {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;} P {font-family:Tahoma,Arial,sans-serif;background:white;color:black;font-size:12px;}A {color : black;}A.name {color : black;}.line {height: 1px; background-color: #525D76; border: none;}</style> </head><body><h1>HTTP Status 500 - FileNotFoundException: https://erddap-be-uncabled.oceanobservatories.org/uncabled/erddap/tabledap/CP01CNSM-SBD12-08-FDCHPA000-fdchp_a_dcl_instrument-telemetered-deployment0007-tabledap.nccsv?time,vw_momentum_flux&amp;time%3E=1501545600.0&amp;time%3C=1501718400.0</h1><div class=\"line\"></div><p><b>type</b> Status report</p><p><b>message</b> <u>FileNotFoundException: https://erddap-be-uncabled.oceanobservatories.org/uncabled/erddap/tabledap/CP01CNSM-SBD12-08-FDCHPA000-fdchp_a_dcl_instrument-telemetered-deployment0007-tabledap.nccsv?time,vw_momentum_flux&amp;time%3E=1501545600.0&amp;time%3C=1501718400.0</u></p><p><b>description</b> <u>The server encountered an internal error that prevented it from fulfilling this request.</u></p><hr class=\"line\"><h3>Apache Tomcat/8.0.33</h3></body></html>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/widgets/lib/python3.6/site-packages/erddapy/url_handling.py\u001b[0m in \u001b[0;36m_urlopen\u001b[0;34m(url, auth, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/widgets/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://erddap-uncabled.oceanobservatories.org/uncabled/erddap/tabledap/CP01CNSM-SBD12-08-FDCHPA000-fdchp_a_dcl_instrument-telemetered-deployment0007-tabledap.csv?time,vw_momentum_flux&time%3E=1501545600.0&time%3C=1501718400.0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2e62e0962639>\u001b[0m in \u001b[0;36mwidget_search_button_handler\u001b[0;34m(change)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mconstraints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"time>=\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time<=\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     update_timeseries_plot(\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandard_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstandard_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-12-cdac0d4b7cb3>\u001b[0m in \u001b[0;36mupdate_timeseries_plot\u001b[0;34m(dataset, standard_name, constraints, title_len)\u001b[0m\n\u001b[1;32m      3\u001b[0m ):\n\u001b[1;32m      4\u001b[0m     df, var = get_data(\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandard_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstandard_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m     \u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a0156b1cdd5a>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(dataset, standard_name, constraints)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     df = pd.read_csv(\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/widgets/lib/python3.6/site-packages/erddapy/url_handling.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, auth, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Ignoring type checks here b/c mypy does not support decorated functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/widgets/lib/python3.6/site-packages/erddapy/url_handling.py\u001b[0m in \u001b[0;36m_urlopen\u001b[0;34m(url, auth, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{response.content.decode()}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: <!DOCTYPE html><html><head><title>Apache Tomcat/8.0.33 - Error report</title><style type=\"text/css\">H1 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:22px;} H2 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:16px;} H3 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:14px;} BODY {font-family:Tahoma,Arial,sans-serif;color:black;background-color:white;} B {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;} P {font-family:Tahoma,Arial,sans-serif;background:white;color:black;font-size:12px;}A {color : black;}A.name {color : black;}.line {height: 1px; background-color: #525D76; border: none;}</style> </head><body><h1>HTTP Status 500 - FileNotFoundException: https://erddap-be-uncabled.oceanobservatories.org/uncabled/erddap/tabledap/CP01CNSM-SBD12-08-FDCHPA000-fdchp_a_dcl_instrument-telemetered-deployment0007-tabledap.nccsv?time,vw_momentum_flux&amp;time%3E=1501545600.0&amp;time%3C=1501718400.0</h1><div class=\"line\"></div><p><b>type</b> Status report</p><p><b>message</b> <u>FileNotFoundException: https://erddap-be-uncabled.oceanobservatories.org/uncabled/erddap/tabledap/CP01CNSM-SBD12-08-FDCHPA000-fdchp_a_dcl_instrument-telemetered-deployment0007-tabledap.nccsv?time,vw_momentum_flux&amp;time%3E=1501545600.0&amp;time%3C=1501718400.0</u></p><p><b>description</b> <u>The server encountered an internal error that prevented it from fulfilling this request.</u></p><hr class=\"line\"><h3>Apache Tomcat/8.0.33</h3></body></html>"
     ]
    }
   ],
   "source": [
    "form_item_layout = ipyw.Layout(\n",
    "    display=\"flex\", flex_flow=\"column\", justify_content=\"space-between\"\n",
    ")\n",
    "\n",
    "col1 = ipyw.Box([map, figure], layout=form_item_layout)\n",
    "col2 = ipyw.Box(\n",
    "    [\n",
    "        widget_std_names,\n",
    "        widget_search_min_time,\n",
    "        widget_search_max_time,\n",
    "        widget_search_button,\n",
    "        ispace,\n",
    "        widget_dsnames,\n",
    "        widget_plot_start_time,\n",
    "        widget_plot_stop_time,\n",
    "        widget_replot_button,\n",
    "    ],\n",
    "    layout=form_item_layout,\n",
    ")\n",
    "\n",
    "form_items = [col1, col2]\n",
    "\n",
    "form = ipyw.Box(\n",
    "    form_items,\n",
    "    layout=ipyw.Layout(\n",
    "        display=\"flex\",\n",
    "        flex_flow=\"row\",\n",
    "        border=\"solid 2px\",\n",
    "        align_items=\"flex-start\",\n",
    "        width=\"100%\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python4widgets",
   "language": "python",
   "name": "widgets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
